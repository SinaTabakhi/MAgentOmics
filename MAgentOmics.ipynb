{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada51b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from sys import float_info\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0665e",
   "metadata": {},
   "source": [
    "# Classes' definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleView:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dataset,              # single view dataset (received as a dataframe)\n",
    "                 init_pheromone_value, # initial pheromone value\n",
    "                 probability_value     # the relative importance of the view\n",
    "                ):\n",
    "        self.dataset = dataset\n",
    "        self._init_pheromone_value = init_pheromone_value\n",
    "        self._probability_value = probability_value\n",
    "\n",
    "    def initialize(self):\n",
    "        # number of features in the view\n",
    "        self._num_features = len(self.dataset.columns)\n",
    "            \n",
    "        # set intensity of pheromone values on each feature\n",
    "        self._pheremone = np.full(self._num_features, self._init_pheromone_value)\n",
    "        \n",
    "        # compute correlation values between each pair of features (Using Pearson correlation coefficient)\n",
    "        self._correlation_matrix = self.dataset.corr(method='pearson')\n",
    "        self._correlation_matrix = self._correlation_matrix.applymap(abs)\n",
    "    \n",
    "        # compute relevance values (Using term variance)\n",
    "        self._relevance = self.dataset.var()\n",
    "\n",
    "    @property\n",
    "    def num_features(self):\n",
    "        return self._num_features\n",
    "    \n",
    "    @property\n",
    "    def probability_value(self):\n",
    "        return self._probability_value\n",
    "                 \n",
    "    @probability_value.setter\n",
    "    def probability_value(self, new_probability_value):\n",
    "        self._probability_value = new_probability_value\n",
    "                 \n",
    "    def get_pheromone(self, feature_index):\n",
    "        return self._pheremone[feature_index]\n",
    "             \n",
    "    def update_pheromone(self, feature_index, new_pheromone_value):\n",
    "        self._pheremone[feature_index] = new_pheromone_value\n",
    "                 \n",
    "    def get_correlation(self, feature_index_1, feature_index_2):\n",
    "        return self._correlation_matrix.iloc[feature_index_1, feature_index_2]\n",
    "    \n",
    "    def get_relevance(self, feature_index):\n",
    "        return self._relevance[feature_index]\n",
    "                 \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "     Number of featurs: {self._num_features}\n",
    "     Pheromone values:  {self._pheremone}\n",
    "     Probability value: {self._probability_value}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fa617",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_selected_features, # number of selected features for each agent\n",
    "                ):\n",
    "        self._num_selected_features = num_selected_features\n",
    "    \n",
    "    def reset(self):\n",
    "        # selected_features is a dictionary in which\n",
    "        # keys show the index of the view and \n",
    "        # values indicate the indeces of the selected featrues in a specific view\n",
    "        self._selected_features = {}\n",
    "        self._last_selected_feature = -1\n",
    "        self._last_selected_view = -1\n",
    "        self._total_relevance_value = 0\n",
    "        self._total_correlation_value = 0\n",
    "        self._total_performance_value = 0\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.reset()\n",
    "\n",
    "    @property\n",
    "    def selected_features(self):\n",
    "        return self._selected_features\n",
    "\n",
    "    @property\n",
    "    def last_selected_feature(self):\n",
    "        return self._last_selected_feature\n",
    "                 \n",
    "    @last_selected_feature.setter\n",
    "    def last_selected_feature(self, value):\n",
    "        self._last_selected_feature = value\n",
    "\n",
    "    @property\n",
    "    def last_selected_view(self):\n",
    "        return self._last_selected_view\n",
    "                 \n",
    "    @last_selected_view.setter\n",
    "    def last_selected_view(self, value):\n",
    "        self._last_selected_view = value\n",
    "    \n",
    "    @property\n",
    "    def total_relevance_value(self):\n",
    "        return self._total_relevance_value\n",
    "        \n",
    "    @property\n",
    "    def total_correlation_value(self):\n",
    "        return self._total_correlation_value\n",
    "\n",
    "    @property\n",
    "    def total_performance_value(self):\n",
    "        return self._total_performance_value\n",
    "                         \n",
    "    def add_next_feature(self, feature_index, view_index, relevance_value, correlation_value = 0):\n",
    "        self._last_selected_feature = feature_index\n",
    "        self._last_selected_view = view_index\n",
    "        \n",
    "        # add the selected feature to the selected_features array\n",
    "        value = self._selected_features.get(view_index, [])\n",
    "        value.append(feature_index)\n",
    "        self._selected_features[view_index] = value\n",
    "        \n",
    "        # update current relevance and correlation values of the agent\n",
    "        self._total_relevance_value += relevance_value\n",
    "        self._total_correlation_value += correlation_value\n",
    "    \n",
    "    def evaluate_feature_subset(self, num_computed_correlation):\n",
    "        self._total_relevance_value /= self._num_selected_features\n",
    "        self._total_correlation_value /= num_computed_correlation\n",
    "        self._total_performance_value = self._total_relevance_value / self._total_correlation_value\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "     Selected features:         {self._selected_features}\n",
    "     Last selected feature:     {self._last_selected_feature}     \n",
    "     Last selected view:        {self._last_selected_view}\n",
    "     Sum of relevance values:   {self._total_relevance_value}\n",
    "     Sum of correlation values: {self._total_correlation_value}\n",
    "     Total performance:         {self._total_performance_value}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgentSystem:\n",
    "    \n",
    "    CORRELATION_ERROR = 0.0001\n",
    "    RELEVANCE_ERROR = 0.0001\n",
    "    \n",
    "    def __init__(self,\n",
    "                 num_iters,             # maximum number of iterations\n",
    "                 num_agents,            # number of agents used in each view (i.e, each omics)\n",
    "                 num_selected_features, # number of selected features for each agent\n",
    "                 views,                 # a list of views (i.e., multi-view/multi-omics dataset)\n",
    "                 alpha,                 # importance of first heuristic information (used in the state transition rule)\n",
    "                 beta,                  # importance of second heuristic information (used in the state transition rule)\n",
    "                 q0,                    # the constant parameter in the state transition rule \n",
    "                                        # (Selection between greedy and probability rules)\n",
    "                 discount_rate          # pheromone evaporation rate\n",
    "                ):\n",
    "        self._num_iters = num_iters\n",
    "        self._num_agents = num_agents\n",
    "        self._num_selected_features = num_selected_features\n",
    "        self._views = views\n",
    "        self._alpha = alpha\n",
    "        self._beta = beta\n",
    "        self._q0 = q0\n",
    "        self._discount_rate = discount_rate\n",
    "        \n",
    "    def initialize(self):\n",
    "        # number of datasets (i.e., number of omics types)\n",
    "        self._num_views = len(self._views)\n",
    "        \n",
    "        # total number of agents used in all views (i.e, all omics)\n",
    "        self._total_num_agents = self._num_agents * self._num_views \n",
    "            \n",
    "        # count the number of times that a specific feature is selected by agents in which\n",
    "        # keys show the indices of the views and \n",
    "        # values indicate dictionaries that count number of times that a specific feature is selected in a specific view\n",
    "        self._feature_counter = {}\n",
    "        \n",
    "        # count the number of correlation values between each pair of features in a feature subset\n",
    "        # this value will be used in computing the agent's performance\n",
    "        self._count_correlation_computation = sum(range(self._num_selected_features))\n",
    "            \n",
    "        # initialize agents \n",
    "        self._agents = []\n",
    "        for agent_index in range(self._total_num_agents):\n",
    "            agent = Agent(self._num_selected_features)\n",
    "            agent.initialize()\n",
    "            self._agents.append(agent)\n",
    "            \n",
    "        # best agent (selected based on the agents' performance)\n",
    "        self._best_selected_features = {}\n",
    "        self._best_performance = 0\n",
    "\n",
    "    @property\n",
    "    def num_iters(self):\n",
    "        return self._num_iters\n",
    "    \n",
    "    @property\n",
    "    def num_selected_features(self):\n",
    "        return self._num_selected_features\n",
    "    \n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self._alpha\n",
    "    \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return self._beta\n",
    "    \n",
    "    @property\n",
    "    def q0(self):\n",
    "        return self._q0\n",
    "\n",
    "    @property\n",
    "    def discount_rate(self):\n",
    "        return self._discount_rate\n",
    "        \n",
    "    @property\n",
    "    def num_views(self):\n",
    "        return self._num_views\n",
    "\n",
    "    @property\n",
    "    def num_agents(self):\n",
    "        return self._num_agents\n",
    "    \n",
    "    @property\n",
    "    def total_num_agents(self):\n",
    "        return self._total_num_agents\n",
    "        \n",
    "    @property\n",
    "    def best_selected_features(self):\n",
    "        return self._best_selected_features\n",
    "    \n",
    "    @best_selected_features.setter\n",
    "    def best_selected_features(self, current_best_set):\n",
    "        self._best_selected_features = current_best_set\n",
    "\n",
    "    @property\n",
    "    def best_performance(self):\n",
    "        return self._best_performance\n",
    "    \n",
    "    @best_performance.setter\n",
    "    def best_performance(self, current_best_performance):\n",
    "        self._best_performance = current_best_performance\n",
    "    \n",
    "    @property\n",
    "    def count_correlation_computation(self):\n",
    "        return self._count_correlation_computation\n",
    "    \n",
    "    @property\n",
    "    def views(self):\n",
    "        return self._views\n",
    "    \n",
    "    @property\n",
    "    def agents(self):\n",
    "        return self._agents\n",
    "    \n",
    "    @property\n",
    "    def feature_counter(self):\n",
    "        return self._feature_counter\n",
    "    \n",
    "    def reset_feature_counter(self):\n",
    "        self._feature_counter = {}\n",
    "    \n",
    "    def update_feature_counter(self, feature_index, view_index):\n",
    "        view_index_value = self._feature_counter.get(view_index, {})\n",
    "        view_index_value[feature_index] = view_index_value.get(feature_index, 0) + 1\n",
    "        self._feature_counter[view_index] = view_index_value\n",
    "\n",
    "    def reset_agents(self):\n",
    "        for agent_index in range(self._total_num_agents):\n",
    "            self._agents[agent_index].reset()\n",
    "    \n",
    "    def get_views_probability(self):\n",
    "        views_probability = []\n",
    "        for view_index in range(self._num_views):\n",
    "            views_probability.append(self._views[view_index].probability_value)\n",
    "        return views_probability\n",
    "       \n",
    "    def set_views_probability(self, views_probability):\n",
    "        for view_index in range(self._num_views):\n",
    "            self._views[view_index].probability_value = views_probability[view_index]\n",
    "    \n",
    "    def set_agents_start_nodes(self):\n",
    "        total_agent_index = 0\n",
    "        for view_index in range(self.num_views):\n",
    "            # generate initial nodes of the agent (unique elements chosen from the list of features)\n",
    "            initial_features = rand.sample(range(self.views[view_index].num_features),self.num_agents)\n",
    "        \n",
    "            for feature_index in initial_features:\n",
    "                relevance_value = self.views[view_index].get_relevance(feature_index)\n",
    "                self.agents[total_agent_index].add_next_feature(feature_index, view_index, relevance_value)\n",
    "                total_agent_index += 1\n",
    "                self.update_feature_counter(feature_index, view_index)\n",
    "    \n",
    "    def select_by_greedy_rule(self, current_agent_index):\n",
    "        agent = self.agents[current_agent_index]\n",
    "        current_selected_features = agent.selected_features.get(agent.last_selected_view, [])\n",
    "        current_view = self.views[agent.last_selected_view]\n",
    "        total_features = current_view.num_features\n",
    "\n",
    "        max_value = -float_info.max\n",
    "        max_index = -1\n",
    "        \n",
    "        for feature_index in range(total_features):\n",
    "            if feature_index not in current_selected_features:\n",
    "                correlation_value = current_view.get_correlation(agent.last_selected_feature, feature_index)\n",
    "                denominator_value = pow(correlation_value + self.CORRELATION_ERROR, self.beta)\n",
    "                numerator_value = pow(current_view.get_relevance(feature_index), self.alpha)\n",
    "                result = (current_view.get_pheromone(feature_index) * numerator_value) / denominator_value\n",
    "                \n",
    "                if result > max_value:\n",
    "                    max_value = result\n",
    "                    max_index = feature_index\n",
    "                    \n",
    "        return agent.last_selected_view, max_index # A tuple (view index, feature index)\n",
    "    \n",
    "    def select_by_probability_rule(self, current_agent_index, views_probability):\n",
    "        # select the next view based on the probability distribution\n",
    "        next_view_index = rand.choices(range(self.num_views), weights=views_probability, k=1)[0]\n",
    "        \n",
    "        # find the candidate features in the selected view for the specific agent\n",
    "        agent = self.agents[current_agent_index]\n",
    "        current_selected_features = agent.selected_features.get(next_view_index, [])\n",
    "        total_features_set = np.arange(self.views[next_view_index].num_features)\n",
    "        candidate_features = np.setdiff1d(total_features_set, current_selected_features)\n",
    "        \n",
    "        current_view = self.views[agent.last_selected_view]\n",
    "        next_view = self.views[next_view_index]\n",
    "            \n",
    "        features_probability = []\n",
    "        sum_of_probabilities = 0\n",
    "        for feature_index in candidate_features:\n",
    "            correlation_value = np.corrcoef(current_view.dataset.iloc[:,agent.last_selected_feature],\n",
    "                                            next_view.dataset.iloc[:,feature_index])[1,0]\n",
    "            correlation_value = abs(correlation_value)\n",
    "            denominator_value = pow(correlation_value + self.CORRELATION_ERROR, self.beta)\n",
    "            numerator_value = pow(next_view.get_relevance(feature_index), self.alpha)\n",
    "            result = (next_view.get_pheromone(feature_index) * numerator_value) / denominator_value\n",
    "            features_probability.append(result)\n",
    "            sum_of_probabilities += result\n",
    "        \n",
    "        features_probability = list(map(lambda x: x/sum_of_probabilities, features_probability))\n",
    "        \n",
    "        # select the next feature based on its probability value\n",
    "        next_feature_index = rand.choices(candidate_features, weights=features_probability, k=1)[0]\n",
    "        \n",
    "        return next_view_index, next_feature_index # A tuple (view index, feature index)\n",
    "\n",
    "    def apply_state_transition_rule(self, current_agent_index, views_probability):\n",
    "        q = np.random.rand()\n",
    "        next_view_index = -1\n",
    "        next_feature_index = -1\n",
    "        \n",
    "        # selection between greedy and probability rules\n",
    "        if (q <= self.q0):\n",
    "            next_view_index, next_feature_index = self.select_by_greedy_rule(current_agent_index)\n",
    "        else:\n",
    "            next_view_index, next_feature_index = self.select_by_probability_rule(current_agent_index, views_probability)\n",
    "          \n",
    "        # compute the correlation values of the new selected feature with previous selected features by agent\n",
    "        agent = self.agents[current_agent_index]\n",
    "        relevance_value = self.views[next_view_index].get_relevance(next_feature_index)\n",
    "        next_feature = self.views[next_view_index].dataset.iloc[:,next_feature_index]\n",
    "        sum_correlation = 0\n",
    "        for view_index in agent.selected_features.keys():\n",
    "            for feature_index in agent.selected_features.get(view_index):\n",
    "                if (view_index != next_view_index) or (feature_index != next_feature_index):\n",
    "                    current_view = self.views[view_index]\n",
    "                    correlation_value = np.corrcoef(current_view.dataset.iloc[:,feature_index], next_feature)[1,0]\n",
    "                    sum_correlation += abs(correlation_value)\n",
    "        \n",
    "        return next_view_index, next_feature_index, sum_correlation, relevance_value\n",
    "    \n",
    "    def evaluate_candidate_subsets(self):\n",
    "        for agent_index in range(self.total_num_agents):\n",
    "            self.agents[agent_index].evaluate_feature_subset(self.count_correlation_computation)\n",
    "    \n",
    "    def update_best_selected_subset(self):\n",
    "        for agent_index in range(self.total_num_agents):\n",
    "            if self.best_performance <= self.agents[agent_index].total_performance_value:\n",
    "                self.best_performance = self.agents[agent_index].total_performance_value\n",
    "                self.best_selected_features = self.agents[agent_index].selected_features\n",
    "    \n",
    "    def update_pheromone_values(self):\n",
    "        view_selected_feature = []\n",
    "        count_selected_feature = self.total_num_agents * self.num_selected_features\n",
    "        \n",
    "        for view_index in range(self.num_views):\n",
    "            current_view = self.views[view_index]\n",
    "            view_index_value = self.feature_counter.get(view_index, {})\n",
    "            best_view_index_value = self.best_selected_features.get(view_index, {})\n",
    "            for feature_index in range(self.views[view_index].num_features):\n",
    "                feature_index_counter = view_index_value.get(feature_index,0)\n",
    "                feature_index_counter /= count_selected_feature\n",
    "                \n",
    "                # add additional quantity to the feature belonging to the best subset\n",
    "                second_term = 0\n",
    "                if feature_index in best_view_index_value:\n",
    "                    second_term = self.best_performance\n",
    "                \n",
    "                second_term += feature_index_counter\n",
    "                second_term *= self.discount_rate\n",
    "                first_term = (1 - self.discount_rate) * current_view.get_pheromone(feature_index)\n",
    "                new_pheromone_value = first_term + second_term\n",
    "\n",
    "                current_view.update_pheromone(feature_index, new_pheromone_value)\n",
    "\n",
    "    def update_views_probability_values(self, views_probability):\n",
    "        view_selected_feature = []\n",
    "        count_selected_feature = 0\n",
    "        \n",
    "        for view_index in range(self.num_views):\n",
    "            view_index_value = self.feature_counter.get(view_index, {})\n",
    "            numerator_value = sum(view_index_value.values())\n",
    "            view_selected_feature.append(numerator_value)\n",
    "            count_selected_feature += numerator_value\n",
    "        \n",
    "        view_selected_feature = list(map(lambda x: self.discount_rate * (x/count_selected_feature), \n",
    "                                         view_selected_feature))\n",
    "        \n",
    "        for view_index in range(self.num_views):\n",
    "            first_term = (1 - self.discount_rate) * views_probability[view_index]\n",
    "            views_probability[view_index] = first_term + view_selected_feature[view_index]\n",
    "        \n",
    "        sum_of_probabilities = sum(views_probability)\n",
    "        views_probability = list(map(lambda x: x/sum_of_probabilities, views_probability))\n",
    "        \n",
    "        self.set_views_probability(views_probability)\n",
    "                \n",
    "    def print_agents(self):\n",
    "        for agent_index in range(self.total_num_agents):\n",
    "            print(f\"     ########## Agent {agent_index} ###########\")\n",
    "            print(self._agents[agent_index])\n",
    "            print(\"     #########################################\")\n",
    "    \n",
    "    def print_views(self):\n",
    "        for view_index in range(self.num_views):\n",
    "            print(f\"     ############# View {view_index} ########\")\n",
    "            print(self.views[view_index])\n",
    "            print(\"     #########################################\")\n",
    "    \n",
    "    def start(self):\n",
    "        for iteration_index in range(self.num_iters):\n",
    "            print(f\"     ------------------------------- Iteration {iteration_index + 1} -------------------------------\")\n",
    "            self.reset_feature_counter()\n",
    "            self.reset_agents()\n",
    "            self.set_agents_start_nodes()\n",
    "            views_probability = self.get_views_probability()\n",
    "            \n",
    "            for feature_index in range(self.num_selected_features - 1):\n",
    "                print(f\"                 ---------- Current selected feature {feature_index + 2} --------------------- \")\n",
    "                for agent_index in range(self.total_num_agents):\n",
    "                    next_view, next_feature, sum_correlation, relevance_value = self.apply_state_transition_rule(agent_index,\n",
    "                                                                                                                 views_probability)\n",
    "                    self.agents[agent_index].add_next_feature(next_feature, next_view, relevance_value, sum_correlation)\n",
    "                    self.update_feature_counter(next_feature, next_view)\n",
    "                \n",
    "            self.evaluate_candidate_subsets()\n",
    "            self.update_best_selected_subset()\n",
    "            self.update_pheromone_values()\n",
    "            self.update_views_probability_values(views_probability)\n",
    "            \n",
    "#             self.print_views()\n",
    "#             self.print_agents()          \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"\"\"\n",
    "     Number of iteration:         {self.num_iters}\n",
    "     Number of selected features: {self.num_selected_features}     \n",
    "     Alpha:                       {self.alpha}\n",
    "     Beta:                        {self.beta}\n",
    "     Q0:                          {self.q0}\n",
    "     Discount rate:               {self.discount_rate}\n",
    "     Number of views:             {self.num_views}\n",
    "     Number of agents:            {self.num_agents}\n",
    "     Total number of agents:      {self.total_num_agents}\n",
    "     Best selected features:      {self.best_selected_features}\n",
    "     Count corr computation:      {self._count_correlation_computation}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81463f",
   "metadata": {},
   "source": [
    "# Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c5f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read DNA_methylation Dataset ()\n",
    "omics1 = pd.read_csv('DataSet_OvarianCancer/DNA_methylation',sep='\\t',index_col=0)\n",
    "omics1 = omics1.transpose()\n",
    "omics1.index.names = ['sample']\n",
    "omics1.columns.names = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read genelevel_copy_number_alteration_CNV Dataset\n",
    "omics2 = pd.read_csv('DataSet_OvarianCancer/genelevel_copy_number_alteration_CNA',sep='\\t',index_col=0)\n",
    "omics2 = omics2.transpose()\n",
    "omics2.index.names = ['sample']\n",
    "omics2.columns.names = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read RNA-Seq Dataset\n",
    "omics3 = pd.read_csv('DataSet_OvarianCancer/RNASeq',sep='\\t',index_col=0)\n",
    "omics3 = omics3.transpose()\n",
    "omics3.index.names = ['sample']\n",
    "omics3.columns.names = ['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894dad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions(s):\n",
    "    if (s['days_to_death'] / 365) >= 3:\n",
    "        return 1\n",
    "    elif s['vital_status'] == 'DECEASED':\n",
    "        return 0\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c765ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read clinical data\n",
    "label = pd.read_csv('DataSet_OvarianCancer/ClinicalMatrix',sep='\\t',index_col=0)\n",
    "label = label[label['days_to_death'].notnull()]\n",
    "label['survival'] = label.apply(conditions, axis=1)\n",
    "label = label[label['survival'] != -1].loc[:, ['survival']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0cc95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f1e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "omics3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be0f3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc36cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4108d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269cf616",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c683c25",
   "metadata": {},
   "source": [
    "# Keep rows (patients) that have values in all omics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6245e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = omics1.index.intersection(omics2.index)\n",
    "common_indices = common_indices.intersection(omics3.index)\n",
    "common_indices = common_indices.intersection(label.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b401f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_full = omics1[omics1.index.isin(common_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8096e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486235c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2_full = omics2[omics2.index.isin(common_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf662b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics3_full = omics3[omics3.index.isin(common_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics3_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155033a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_full = label[label.index.isin(common_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f153b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"long-term survivors= \", sum(label_full['survival'] == 1))\n",
    "print(\"short-term survivors= \", sum(label_full['survival'] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb945ef3",
   "metadata": {},
   "source": [
    "# Sort dataframes based on their indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final = omics1_full.sort_index(axis=0)\n",
    "omics2_final = omics2_full.sort_index(axis=0)\n",
    "omics3_final = omics3_full.sort_index(axis=0)\n",
    "label_final = label_full.sort_index(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f66476",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37827d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27757412",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics3_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10228a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_final.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bed847",
   "metadata": {},
   "source": [
    "# Pre-Filtered Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6e7f9c",
   "metadata": {},
   "source": [
    "# 1. Removed features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final = omics1_final.dropna(axis=1)\n",
    "omics2_final = omics2_final.dropna(axis=1)\n",
    "omics3_final = omics3_final.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be0bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNA_methylation Dataset\n",
    "print('#Remained features = ', len(omics1_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genelevel_copy_number_alteration_CNA Dataset\n",
    "print('#Remained features = ', len(omics2_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c45cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNASeq Dataset\n",
    "print('#Remained features = ', len(omics3_final.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7d8ad",
   "metadata": {},
   "source": [
    "# 2.  Rescale feature values to lie in the interval [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95cbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the min-max scaling in Pandas using the .min() and .max() methods\n",
    "def min_max_scaling(df):\n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        col_min_value = df_norm[column].min()\n",
    "        col_max_value = df_norm[column].max()\n",
    "        df_norm[column] = (df_norm[column] - col_min_value) / (col_max_value - col_min_value)\n",
    "        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbe24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final = min_max_scaling(omics1_final)\n",
    "omics2_final = min_max_scaling(omics2_final)\n",
    "omics3_final = min_max_scaling(omics3_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0ba98d",
   "metadata": {},
   "source": [
    "# 3. Remove features with variance less than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final = omics1_final.loc[:,omics1_final.var() >= 0.05]\n",
    "omics2_final = omics2_final.loc[:,omics2_final.var() >= 0.05]\n",
    "omics3_final = omics3_final.loc[:,omics3_final.var() >= 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics1_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1822641",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics2_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics3_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79673fb",
   "metadata": {},
   "source": [
    "# Split dataset into test and training sets\n",
    "# Apply Multi-agent algorithm\n",
    "# Find the best candidate feature subset\n",
    "# Reduce the dataset\n",
    "# Evaluate the method by different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65cdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = {}\n",
    "    models[0] = LogisticRegression()\n",
    "    models[1] = RandomForestClassifier()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ab1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted_results = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted_results)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b73b0e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# settings of Multi Agent algorithm\n",
    "init_pheromone_value = 0.2\n",
    "num_views = 3\n",
    "probability_value = 1.0 / num_views\n",
    "\n",
    "num_iters = 30\n",
    "num_agents = 20\n",
    "alpha = 2\n",
    "beta = 2\n",
    "q0 = 0.7\n",
    "discount_rate = 0.2\n",
    "feature_sizes = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "# repeat algorithm for different sizes of feature subsets\n",
    "for feature_size in feature_sizes:\n",
    "    print(\"\\n\\n***************************************************************\")\n",
    "    print(f\"********************* Feature size {feature_size} *************************\")\n",
    "    print(\"***************************************************************\")\n",
    "    model_acc = {}\n",
    "    # configurations to repeat the k-fold cross-validation process (designed for imbalanced Classification)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=1)\n",
    "    for train_index, test_index in cv.split(omics1_final, y=label_final):\n",
    "        # split datasets into training and test sets\n",
    "        omics1_final_train, omics1_final_test = omics1_final.iloc[train_index], omics1_final.iloc[test_index]\n",
    "        omics2_final_train, omics2_final_test = omics2_final.iloc[train_index], omics2_final.iloc[test_index]\n",
    "        omics3_final_train, omics3_final_test = omics3_final.iloc[train_index], omics3_final.iloc[test_index]\n",
    "        label_final_train,  label_final_test  = label_final.iloc[train_index],  label_final.iloc[test_index]\n",
    "    \n",
    "        # create initial views of each dataset\n",
    "        omics_view1 = SingleView(omics1_final_train, init_pheromone_value, probability_value)\n",
    "        omics_view2 = SingleView(omics2_final_train, init_pheromone_value, probability_value)\n",
    "        omics_view3 = SingleView(omics3_final_train, init_pheromone_value, probability_value)\n",
    "        omics_view1.initialize()\n",
    "        omics_view2.initialize()\n",
    "        omics_view3.initialize()\n",
    "        \n",
    "        # start the integration feature selection algorithm using Multi Agent system\n",
    "        views = [omics_view1, omics_view2, omics_view3]\n",
    "        alg = MultiAgentSystem(num_iters,\n",
    "                               num_agents,\n",
    "                               feature_size, \n",
    "                               views,\n",
    "                               alpha,\n",
    "                               beta,\n",
    "                               q0, \n",
    "                               discount_rate)\n",
    "        alg.initialize()\n",
    "        print(alg)\n",
    "        alg.start()\n",
    "        final_subset = alg.best_selected_features\n",
    "\n",
    "        print(f\"\\n\\n     Final selected subset: {final_subset}\")\n",
    "        \n",
    "        # create reduced datasets based on final selected features\n",
    "        feature_indices_view1 = final_subset.get(0, [])\n",
    "        omics1_reduced_train = omics1_final_train.iloc[:,feature_indices_view1]\n",
    "        omics1_reduced_test = omics1_final_test.iloc[:,feature_indices_view1]\n",
    "    \n",
    "        feature_indices_view2 = final_subset.get(1, [])\n",
    "        omics2_reduced_train = omics2_final_train.iloc[:,feature_indices_view2]\n",
    "        omics2_reduced_test = omics2_final_test.iloc[:,feature_indices_view2]\n",
    "        \n",
    "        feature_indices_view3 = final_subset.get(2, [])\n",
    "        omics3_reduced_train = omics3_final_train.iloc[:,feature_indices_view3]\n",
    "        omics3_reduced_test = omics3_final_test.iloc[:,feature_indices_view3]\n",
    "    \n",
    "    \n",
    "        final_train_dataset = pd.concat([omics1_reduced_train, omics2_reduced_train, omics3_reduced_train], axis=1)\n",
    "        final_test_dataset = pd.concat([omics1_reduced_test, omics2_reduced_test, omics3_reduced_test], axis=1)       \n",
    "        \n",
    "        \n",
    "        # get the list of models to evaluate performance\n",
    "        models = get_models()\n",
    "        # evaluate each model\n",
    "        new_output_file_lines = f\"Feature size: {feature_size}\"\n",
    "        for model_index in models:\n",
    "            acc = evaluate_model(models[model_index], \n",
    "                                 X_train=final_train_dataset.values,\n",
    "                                 X_test=final_test_dataset.values,\n",
    "                                 y_train=label_final_train.values.ravel(),\n",
    "                                 y_test=label_final_test.values.ravel())\n",
    "            value = model_acc.get(model_index, [])\n",
    "            value.append(acc)\n",
    "            model_acc[model_index] = value\n",
    "            print(f\"     Classifier index ({model_index}) --> classification accuracy: {acc}\")\n",
    "            new_output_file_lines += f\"\\nClassifier index ({model_index}) --> classification accuracy {model_acc[model_index]}\"\n",
    "\n",
    "        # write the current results in the output file\n",
    "        output_file_lines = \"\"\n",
    "        try:\n",
    "            output_file_lines = open(\"output_multi_agent.txt\", 'r').readlines()\n",
    "            output_file_lines[-3:] = new_output_file_lines\n",
    "        except Exception:\n",
    "            output_file_lines = new_output_file_lines\n",
    "        \n",
    "        open(\"output_multi_agent.txt\", 'w').writelines(output_file_lines)\n",
    "         \n",
    "            \n",
    "        print(\"     ###########################################################################\")\n",
    "        print(\"     ###########################################################################\")\n",
    "    \n",
    "    # prepare the output file for the next feature size\n",
    "    try:\n",
    "        output_file_lines = open(\"output_multi_agent.txt\", 'r').readlines()\n",
    "        output_file_lines.append(\"\\n\\n\\n\\n\\n\")\n",
    "        open(\"output_multi_agent.txt\", 'w').writelines(output_file_lines)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    print(f\"Final classification accuracies for {feature_size} selected features\")\n",
    "    for model_index in model_acc:\n",
    "        print(f\"     Classifier index ({model_index}) --> classification accuracy: {model_acc[model_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
